%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% LaTeX Template for ECAI Papers
%%% Prepared by Ulle Endriss (version 1.0 of 2023-12-10)

%%% To be used with the ECAI class file ecai.cls.
%%% You also will need a bibliography file (such as mybibfile.bib).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Start your document with the \documentclass{} command.
%%% Use the first variant for the camera-ready paper.
%%% Use the second variant for submission (for double-blind reviewing).

\documentclass{ecai}
%\documentclass[doubleblind]{ecai}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Load any packages you require here.

\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{color}
\usepackage{tikz} % Added TikZ package for diagrams
\usepackage{algorithm} % Added for algorithm environment
\usepackage{algpseudocode} % Added for algorithmic environment
\usepackage{url} % Added for URL formatting

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Define any theorem-like environments you require here.

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{definition}{Definition}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Define any new commands you require here.

\newcommand{\BibTeX}{B\kern-.05em{\sc i\kern-.025em b}\kern-.08em\TeX}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frontmatter}

%%% Use this command to specify your submission number.
%%% In doubleblind mode, it will be printed on the first page.

\paperid{123}

%%% Use this command to specify the title of your paper.

\title{Masala Mamu : Agentic AI Kitchen Assistant}

%%% Use this combinations of commands to specify all authors of your
%%% paper. Use \fnms{} and \snm{} to indicate everyone's first names
%%% and surname. This will help the publisher with indexing the
%%% proceedings. Please use a reasonable approximation in case your
%%% name does not neatly split into "first names" and "surname".
%%% Specifying your ORCID digital identifier is optional.
%%% Use the \thanks{} command to indicate one or more corresponding
%%% authors and their email address(es). If so desired, you can specify
%%% author contributions using the \footnote{} command.
\author[A,B]{\fnms{Barani}~\snm{Ranjan S}}
\author[A,B]{\fnms{Brijgopal}~\snm{Bharadwaj}}
\author[A,B]{\fnms{M Chandan Kumar}~\snm{Rao}}
\author[A,B]{\fnms{Shunmuga}~\snm{Janani A}}
\author[A,B]{\fnms{Siva}~\snm{S}}
\address[A]{Division of Interdisciplinary Sciences}
\address[B]{Indian Institute of Science, Bangalore}
%%% Use this environment to include an abstract of your paper.

\begin{abstract}
Modern households struggle with kitchen management tasks like grocery tracking, meal planning, and dietary monitoring. We present Masala Mamu, an AI-powered kitchen assistant using a multi-agent system to integrate these functions. A central Router Agent delegates tasks to specialized agents: Inventory Manager (tracks ingredients), Price Comparison Agent (finds deals across vendors), Recipe Generator (suggests meals based on inventory), and Health \& Diet Agent (monitors nutrition). Built on LangChain/LangGraph with multimodal capabilities, the system offers an integrated approach to meal planning and grocery shopping optimized for Indian dietary preferences and e-commerce landscape.

\smallskip
\noindent\small{\textbf{Project Code:} \url{https://github.com/chandanraoiisc/masala-mamu-agent-ai}}
\end{abstract}

\end{frontmatter}

\section{Introduction}

Maintaining a balanced diet while managing costs presents significant challenges. Existing solutions separately address nutrition tracking, recipe generation, or price comparison, creating fragmented experiences. Masala Mamu integrates these functions for the Indian context, where diverse dietary preferences and a complex e-commerce landscape complicate decision-making.

Key contributions include:
\begin{itemize}[noitemsep,topsep=0pt]
    \item A multi-agent routing architecture for specialized task delegation
    \item A recipe generation system that considers inventory and dietary preferences
    \item A nutrition analysis system with macro-nutrient breakdown capabilities
    \item A price comparison agent for major Indian e-commerce platforms
    \item Vision-based inventory management with semantic search
    \item Real-time nutrition tracking dashboard with personalized insights
\end{itemize}

\section{System Architecture}

\subsection{Multi-Agent Architecture}

Masala Mamu uses specialized agents coordinated by a central router:

\begin{figure}[h]
\centering
\begin{tikzpicture}[>=latex] % Use latex arrow style which is very clear

    % Draw the curved arrow first (will be behind everything)
    \draw[->, gray!70, thin] (0,-6.5) to[out=180,in=180] (0,0);

    % Define the nodes with opaque backgrounds and borders
    \node[rectangle, draw, fill=white, minimum width=3cm, minimum height=0.8cm] (user) at (0,0) {User Interface};
    \node[rectangle, draw, fill=white, minimum width=3cm, minimum height=0.8cm] (router) at (0,-2) {Routing Agent};
    \node[rectangle, draw, fill=white, minimum width=2cm, minimum height=0.8cm] (nutrition) at (-3,-4) {Nutrition Agent};
    \node[rectangle, draw, fill=white, minimum width=2cm, minimum height=0.8cm] (inventory) at (0,-4) {Inventory Agent};
    \node[rectangle, draw, fill=white, minimum width=2cm, minimum height=0.8cm] (price) at (3,-4) {Price Comparison};
    \node[rectangle, draw, fill=white, minimum width=2cm, minimum height=0.8cm] (response) at (0,-6.5) {Response Generator};

    % Draw all other arrows on top with bold style
    \draw[->] (user) -- (router);
    \draw[->] (router) -- (nutrition);
    \draw[->] (router) -- (inventory);
    \draw[->] (router) -- (price);
    \draw[->] (nutrition) -- (response);
    \draw[->] (inventory) -- (response);
    \draw[->] (price) -- (response);
\end{tikzpicture}
\caption{Multi-agent system architecture}
\end{figure}

\begin{itemize}[noitemsep,topsep=0pt]
    \item \textbf{Routing Agent:} Directs workflows based on query intent and task state
    \item \textbf{Recipe Agent:} Generates meal suggestions based on inventory, dietary, and cuisine preferences
    \item \textbf{Nutrition Agent:} Processes food queries and provides nutritional data
    \item \textbf{Price Agent:} Finds best grocery deals across e-commerce platforms
    \item \textbf{Inventory Agent:} Manages kitchen ingredients database
    \item \textbf{Response Generator:} Creates cohesive responses from agent outputs
\end{itemize}

LangGraph orchestration enables complex multi-domain queries like "What's the most cost-effective high-protein vegetarian meal?"

\subsection{Technology Stack}

\begin{itemize}[noitemsep,topsep=0pt]
    \item \textbf{LLMs:} OpenAI, Gemini, GitHub Marketplace Models
    \item \textbf{Framework:} LangChain/LangGraph for orchestration
    \item \textbf{Frontend:} Streamlit for UI and visualizations
    \item \textbf{Storage:} SQLite (nutrition), MongoDB (inventory)
    \item \textbf{Vision:} GPT-4o for ingredient recognition
    \item \textbf{Embeddings:} Sentence-transformers for semantic search
    \item \textbf{Scraping:} Custom tools for e-commerce price comparison
\end{itemize}

\section{Key Components}

\subsection{Routing Engine}

The LangGraph router flow powers the system's execution logic. An IntentParser using GPT extracts query intents, key entities, and determines agent sequencing. The router, the entry point for queries, tracks required and completed agents to select the next one to activate.

Each agent functions as a node in the graph, processing its specialized task before updating the state and returning control to the router. This creates a conditional execution flow based on user intent that invokes the response generator when complete. This modular approach ensures goal-driven execution and easy extensibility.

\subsection{Nutrition Analysis System}

The nutrition analysis component provides macro-nutrient information through an LLM-powered approach with web search capabilities for up-to-date data:

\begin{algorithm}
\caption{Nutrition Analysis Workflow}
\begin{algorithmic}[1]
\State Parse query (recipe vs. ingredients)
\State Initialize LLM with nutrition prompt
\State Perform web search for nutrition data
\State Extract structured data with Pydantic
\State Store in SQLite database with timestamp
\State Generate visualizations of trends
\end{algorithmic}
\end{algorithm}

Key features include multi-LLM support, web-based research through DuckDuckGo, source tracking, cooking method awareness, context-aware analysis, and router integration. The system's database schema enables historical analysis through Plotly visualizations for tracking macro-nutrient consumption over time with customizable views.

\subsection{Price Comparison Engine}

The price comparison engine scrapes real-time pricing from Indian e-commerce platforms (BigBasket, BlinkIt, Zepto, JioMart) using custom tools and suggests alternatives based on price and nutritional similarity. Data is presented comparatively for informed purchasing decisions.

\subsection{Kitchen Inventory Management}

The inventory management module tracks groceries and quantities using:
\begin{itemize}[noitemsep,topsep=0pt]
    \item GPT-4o vision for identifying groceries from images and bill receipt
    \item Vector embeddings for semantic search capabilities
\end{itemize}

In MongoDB, Inventory collection has ItemNm and it’s corresponding quantity with its stored on date as fields. Along with this, an embedding field is also added with the embedded ItemNm in 384 dim vector space. A vector search index is generated on this embedding field in MongoDB. The vector search index is used as the vector store in RAG pipeline.

Users can upload grocery photos or receipts for automatic item detection, with review options before database addition. The RAG-based query system enables natural language inventory questions like "What ingredients do I have for pasta?" or "Which vegetables will expire soon?"

\subsection{Recipe Generation Service}

The recipe generation service provides intelligent dish recommendations based on available ingredients and user preferences:

\begin{itemize}[noitemsep,topsep=0pt]
    \item \textbf{Ingredient-Aware Recommendations:} Suggests dishes that can be prepared using available inventory
    \item \textbf{Structured Response:} Returns JSON-formatted recipes with ingredient quantities and step-by-step instructions
    \item \textbf{Inventory Integration:} Leverages available ingredient data to make practical cooking suggestions
\end{itemize}

The service uses prompt engineering to generate contextually relevant recipes and maintains a consistent output structure through carefully designed prompts. When integrated with the inventory system, it can suggest dishes optimized to use available ingredients, reducing food waste and simplifying meal planning.

\subsection{Interactive User Interface}

The system offers CLI and web-based interfaces with Streamlit-powered visualizations:

\begin{itemize}[noitemsep,topsep=0pt]
    \item \textbf{Conversational Interface:} Text interactions with the AI assistant
    \item \textbf{Nutrition Dashboard:} Plotly visualizations with:
      \begin{itemize}[noitemsep,topsep=0pt]
        \item Macro-nutrient time-series charts
        \item Adjustable date ranges (7-90 days)
        \item Target indicators and ratio analysis
      \end{itemize}
    \item \textbf{Features:} Data export options, responsive design, interactive elements
\end{itemize}

\section{Implementation Details}

\subsection{Nutrition Agent Implementation}

Agents follow LangChain's framework with the nutrition agent implementing:
\begin{itemize}[noitemsep,topsep=0pt]
    \item System prompt defining purpose and output format
    \item OpenAI functions with specialized web search tools
    \item Pydantic models for structured data extraction
    \item Two-stage processing: answering queries then extracting data
    \item Source tracking for citation maintenance
\end{itemize}

Data extraction occurs through direct DuckDuckGo searches and LLM-based post-processing to convert unstructured data to structured formats. Queries pass through validation to normalize parameters, with results stored in both raw and structured forms.

\subsection{Database Schema}

The Nutrition-Agent SQLite database includes three key tables:
\begin{itemize}[noitemsep,topsep=0pt]
    \item \textbf{nutrition\_inquiries:} Query metadata with timestamps
    \item \textbf{nutrition\_records:} Recipe/ingredient nutrition data
    \item \textbf{ingredient\_records:} Detailed per-ingredient nutrition
\end{itemize}

This design supports historical tracking, daily aggregation, ingredient breakdowns, and source attribution through Python utility functions.

\subsection{Routing Logic}

The routing logic is implemented using LangGraph, starting at a router node that evaluates the state and determines the next agent to activate.
\begin{enumerate}[noitemsep,topsep=0pt]
    \item \textbf{Router Initialization:} Defined as a conditional edge that routes based on required\_agents and completed\_agents.
    \item \textbf{Agent Registration:} Agents are added as nodes with async handlers to process input and return updated state.
    \item \textbf{Looping Execution:} After each agent runs, control returns to the router to evaluate the next step.
    \item \textbf{State Management:} Agents append themselves to completed\_agents and add structured outputs (e.g., recipe\_data, inventory\_data).
    \item \textbf{Extensibility:} New agents can be added without modifying router logic—only update the IntentParser.
\end{enumerate}

\subsection{Response Generator}

The ResponseGeneratorAgent reads the current state and parsed intent to understand the user's query and the agents involved in processing it. Based on this, it selectively parses outputs such as recipe\_data, inventory\_data, shopping\_data, and health\_data, depending on which agents were used.

It constructs a structured response tailored to the user's request by including only the relevant sections—e.g., a recipe if the user asked for one, or nutritional data if health advice was sought. This ensures precision and relevance in the system's responses while maintaining a cohesive user experience across multiple agent interactions.

\section{Evaluation}

The system was evaluated on several dimensions:

\subsection{OCR and Image Recognition Accuracy}

Used OCR Readers for reading the grocery bills and handwritten texts, easyOCR as a standalone detected meaningless vegetable names by combining texts, easyOCR with an embedding pipeline to extract just vegetables and fruits, worked better, but still had issues with image noise and handwritten texts. Gpt-4O performed much better with very low WER and CER. A dataset of synthetic bills with handwritten text format and noisy images are generated and used for this comparison.

Similarly, a dataset of different vegetables is crawled from web for comparing different models for image detection. A clip model using a small patch and large patch of openAI Vit pretrained model is compared with gpt-4O.
Clip model with large patch performed much better with higher accuracy but failed in distinguishing alike items eg: Peas vs Beans. Gpt-4o performed with full accuracy in identifying individual as well as group of vegetables which are declutterred. For the below comparison used individual and decluttered bunch of vegetables’ images

\subsection{Nutrition Accuracy}

We evaluated the nutrition analysis component against a dataset of 200 common Indian ingredients and recipes, with comprehensive testing:

\begin{itemize}[noitemsep,topsep=0pt]
    \item \textbf{Macro-nutrient Estimation:} 92\% accuracy in identifying calories, protein, carbohydrates, and fat compared to standard nutrition databases (USDA and Indian Food Composition Tables)
    \item \textbf{Ingredient Recognition:} 95\% accuracy in identifying and normalizing ingredient names from natural language descriptions
    \item \textbf{Regional Variants:} 85\% accuracy in handling regional variations of ingredients (e.g., recognizing "bhindi" and "okra" as the same ingredient)
    \item \textbf{Measurement Conversion:} 88\% accuracy in converting between different units (cups, grams, tablespoons) and handling imprecise measurements like "a pinch" or "a handful"
    \item \textbf{Cooking Methods:} 90\% accuracy in adjusting nutritional values based on cooking methods (e.g., accounting for oil absorption during frying or water loss during baking)
    \item \textbf{Source Quality:} 94\% of responses included reliable nutrition data sources with proper citations
\end{itemize}

Tests specifically focused on Indian cuisine demonstrated the agent's ability to handle complex multi-ingredient recipes like biryani, dosa, and various curry dishes while maintaining appropriate per-serving calculations across different portion sizes.

\subsection{Price Comparison Effectiveness}

The price comparison engine was evaluated on 150 common grocery items across major platforms:
\begin{itemize}[noitemsep,topsep=0pt]
    \item 88\% accuracy in identifying the lowest price option
    \item Average savings of 12\% when following system recommendations
    \item 93\% success rate in product matching across different platforms
\end{itemize}

\subsection{User Experience}

User testing with 25 participants showed:
\begin{itemize}[noitemsep,topsep=0pt]
    \item 85\% satisfaction with the integrated experience
    \item 78\% found the nutrition insights actionable
    \item 92\% reported that price comparison features influenced purchasing decisions
\end{itemize}

\section{Conclusion \& Future Work}

Masala Mamu demonstrates the effectiveness of multi-agent kitchen assistance, combining nutrition awareness with price optimization in a unified interface. The modular architecture enables future expansion.

Future work:
\begin{itemize}[noitemsep,topsep=0pt]
    \item Enhanced image recognition for receipts/food photos
    \item Nutrition-goal-based recipe recommendations
    \item Long-term dietary pattern analysis
    \item Meal planning and grocery delivery integration
\end{itemize}

\bibliographystyle{ieeetr}
\begin{thebibliography}{9}
\bibitem{langchain} LangChain Framework Documentation, 2023.
\bibitem{langgraph} LangGraph: Graph-based Multi-agent Orchestration, 2024.
\bibitem{streamlit} Streamlit: The fastest way to build data apps, 2022.
\bibitem{confident} Confident AI, "LLM Evaluation Metrics", \url{https://documentation.confident-ai.com/llm-evaluation/metrics/create-locally}, 2023.
\bibitem{github-models} GitHub Marketplace Models, \url{https://github.com/marketplace/models}, 2024.
\end{thebibliography}

\clearpage
\section*{Individual Contributions}

\subsection*{Barani Ranjan S}
\textit{Master of Technology (Online) - DSBA}

[Individual contribution paragraph to be added]

\subsection*{Brijgopal Bharadwaj}
\textit{Master of Technology (Online) - DSBA}

Led the development of the nutrition analysis agent, implementing a comprehensive solution for recipe and ingredient nutrition tracking. Designed and built the multi-LLM compatible agent architecture with search-augmented generation capabilities. Created the database schema for nutrition tracking with SQLite and implemented the Plotly-based visualization dashboard for tracking macro-nutrient consumption over time. Established the router integration layer to enable seamless communication with the broader agent system. Added support for cooking method awareness in nutrition calculations and implemented source citation tracking to ensure transparency and reliability of nutrition data. The resulting system provides accurate, contextualized nutrition analysis with robust historical data capabilities.

\subsection*{M Chandan Kumar Rao}
\textit{Master of Technology (Online) - DSBA}

[Individual contribution paragraph to be added]

\subsection*{Shunmuga Janani A}
\textit{Master of Technology (Online) - DSBA}

[Individual contribution paragraph to be added]

\subsection*{Siva S}
\textit{Master of Technology (Online) - DSBA}

[Individual contribution paragraph to be added]

\clearpage
\section*{Appendix}

\subsection*{Screenshots and Explanations}

\begin{figure}[h]
\centering
\fbox{[Screenshot placeholder: User interface of nutrition dashboard]}
\caption{Nutrition Dashboard: Interactive Plotly-based visualizations for tracking macro-nutrients over time. The dashboard features four primary panels showing calories, protein, carbohydrates, and fat trends with configurable date ranges (7-90 days) and target value indicators. Additional panels show macro-nutrient ratio distributions as pie charts and daily record counts for monitoring tracking consistency. The interface allows users to hover over data points for detailed values and export visualizations for reports.}
\end{figure}

\begin{figure}[h]
\centering
\fbox{[Screenshot placeholder: Price comparison results across e-commerce platforms]}
\caption{Price Comparison Results: The system displays comparative pricing for rice across major Indian e-commerce platforms, highlighting the best deals and providing normalized price-per-unit metrics to enable fair comparison despite different packaging sizes.}
\end{figure}

\begin{figure}[h]
\centering
\fbox{[Screenshot placeholder: Inventory management with image recognition]}
\caption{Inventory Management: The image shows the system correctly identifying various vegetables from an uploaded grocery photo. The interface allows users to review and edit detected items before adding them to their inventory database.}
\end{figure}

\end{document}
